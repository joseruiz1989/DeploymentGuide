{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_01_MNIST_tensorflow.ipynb","provenance":[{"file_id":"1Te5CRFMFYFYWSFvGaBfcJIic9_izi3Ry","timestamp":1572898870727}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fgkMFRoQASBT","colab_type":"text"},"source":["# **MNIST classification with TensorFlow model**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ba038bKDe6Gj"},"source":["Predictions "]},{"cell_type":"code","metadata":{"id":"UXlNkYHZfx_z","colab_type":"code","outputId":"772ecb45-b3f8-45c0-ab98-2a59b57de279","executionInfo":{"status":"ok","timestamp":1572971788640,"user_tz":180,"elapsed":2004,"user":{"displayName":"Jose Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDMx7drLG0p8pxb2UEdA7ugLdO4AHvyD0Nl0ilMNAw=s64","userId":"14207732478454182689"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import tensorflow as tf\n","\n","# Import MNIST data\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","import matplotlib.pyplot as plt     # only to show the images at end\n","from numpy.random import randint    # only to generate a random nuymber ar end\n","from numpy import argmax"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting /tmp/data/train-images-idx3-ubyte.gz\n","Extracting /tmp/data/train-labels-idx1-ubyte.gz\n","Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n","Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Km4ba2udCHqk","colab_type":"text"},"source":["set the basic configurations, load the MNIST database and convert it to the necessary format"]},{"cell_type":"code","metadata":{"id":"zSgeT8L4frJf","colab_type":"code","colab":{}},"source":["# Training Parameters\n","learning_rate = 0.001\n","num_steps = 500\n","batch_size = 128\n","display_step = 100\n","\n","# Network Parameters\n","num_input = 784 # MNIST data input (img shape: 28*28)\n","num_classes = 10 # MNIST total classes (0-9 digits)\n","dropout = 0.75 # Dropout, probability to keep units\n","\n","# tf Graph input\n","X = tf.placeholder(tf.float32, [None, num_input])\n","Y = tf.placeholder(tf.float32, [None, num_classes])\n","keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n","\n","# load the data\n","mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmdR3lUFy1Nl","colab_type":"code","colab":{}},"source":["# Create some wrappers for simplicity\n","def conv2d(x, W, b, strides=1):\n","    # Conv2D wrapper, with bias and relu activation\n","    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n","    x = tf.nn.bias_add(x, b)\n","    return tf.nn.relu(x)\n","\n","\n","def maxpool2d(x, k=2):\n","    # MaxPool2D wrapper\n","    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n","                          padding='SAME')\n","\n","\n","# Create model\n","def conv_net(x, weights, biases, dropout):\n","    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n","    # Reshape to match picture format [Height x Width x Channel]\n","    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n","    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n","\n","    # Convolution Layer\n","    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n","    # Max Pooling (down-sampling)\n","    conv1 = maxpool2d(conv1, k=2)\n","\n","    # Convolution Layer\n","    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n","    # Max Pooling (down-sampling)\n","    conv2 = maxpool2d(conv2, k=2)\n","\n","    # Fully connected layer\n","    # Reshape conv2 output to fit fully connected layer input\n","    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n","    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n","    fc1 = tf.nn.relu(fc1)\n","    # Apply Dropout\n","    fc1 = tf.nn.dropout(fc1, dropout)\n","\n","    # Output, class prediction\n","    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXY8iApRy1Kp","colab_type":"code","colab":{}},"source":["# Store layers weight & bias\n","weights = {\n","    # 5x5 conv, 1 input, 32 outputs\n","    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n","    # 5x5 conv, 32 inputs, 64 outputs\n","    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n","    # fully connected, 7*7*64 inputs, 1024 outputs\n","    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n","    # 1024 inputs, 10 outputs (class prediction)\n","    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n","}\n","\n","biases = {\n","    'bc1': tf.Variable(tf.random_normal([32])),\n","    'bc2': tf.Variable(tf.random_normal([64])),\n","    'bd1': tf.Variable(tf.random_normal([1024])),\n","    'out': tf.Variable(tf.random_normal([num_classes]))\n","}\n","\n","# Construct model\n","logits = conv_net(X, weights, biases, keep_prob)\n","prediction = tf.nn.softmax(logits)\n","\n","# Define loss and optimizer\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n","    logits=logits, labels=Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","\n","# Evaluate model\n","correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# Initialize the variables (i.e. assign their default value)\n","init = tf.global_variables_initializer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fw9I4ReMy1Hs","colab_type":"code","outputId":"03c6768c-56f1-445f-f912-bc08582a84fb","executionInfo":{"status":"ok","timestamp":1572971796155,"user_tz":180,"elapsed":9494,"user":{"displayName":"Jose Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDMx7drLG0p8pxb2UEdA7ugLdO4AHvyD0Nl0ilMNAw=s64","userId":"14207732478454182689"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# Start training\n","sess = tf.Session()\n","sess.run(init)\n","for step in range(1, num_steps+1):\n","  batch_x, batch_y = mnist.train.next_batch(batch_size)\n","  # Run optimization op (backprop)\n","  sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n","  if step % display_step == 0 or step == 1:\n","    # Calculate batch loss and accuracy\n","    loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n","                                                        Y: batch_y,\n","                                                        keep_prob: 1.0})\n","    print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n","      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n","      \"{:.3f}\".format(acc))\n","\n","print(\"Optimization Finished!\")\n","\n","# Calculate accuracy for 256 MNIST test images\n","print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: mnist.test.images[:256], Y: mnist.test.labels[:256], keep_prob: 1.0}))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Step 1, Minibatch Loss= 56643.2227, Training Accuracy= 0.195\n","Step 100, Minibatch Loss= 1838.6912, Training Accuracy= 0.898\n","Step 200, Minibatch Loss= 1521.7637, Training Accuracy= 0.898\n","Step 300, Minibatch Loss= 1877.2361, Training Accuracy= 0.930\n","Step 400, Minibatch Loss= 769.2847, Training Accuracy= 0.969\n","Step 500, Minibatch Loss= 552.1393, Training Accuracy= 0.953\n","Optimization Finished!\n","Testing Accuracy: 0.96484375\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LEqhYsnmDDD6","colab_type":"text"},"source":["Predictions "]},{"cell_type":"code","metadata":{"id":"YPOP6yjsy1B5","colab_type":"code","outputId":"d4a7a59c-3178-4bc2-d8ea-9896b310fcb6","executionInfo":{"status":"ok","timestamp":1572971796156,"user_tz":180,"elapsed":9491,"user":{"displayName":"Jose Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDMx7drLG0p8pxb2UEdA7ugLdO4AHvyD0Nl0ilMNAw=s64","userId":"14207732478454182689"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["i=randint(1, mnist.test.images.shape[0])\n","print(i)\n","plt.imshow(mnist.test.images[i].reshape((28,28)), cmap='Greys')    #  cmap='Greys' to show as greyscale\n","print(\"prediction: \", argmax(sess.run(prediction, feed_dict={X: mnist.test.images[i:i+1], keep_prob: 1.0})))\n","print(\"real value: \", argmax(mnist.test.labels[i:i+1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6790\n","prediction:  3\n","real value:  3\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njqnrGgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}